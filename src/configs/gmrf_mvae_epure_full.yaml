# Full training configuration for GMRF MVAE with EPURE dataset
# Architecture matches ICTAI implementation exactly

model:
  type: gmrf_mvae
  num_components: 5            # EPURE: 5 components (without 'gi')
  latent_dim: 4                # ICTAI original
  nf: 32                       # Base number of filters
  nf_max_e: 512                # Encoder max filters
  nf_max_d: 256                # Decoder max filters (different from encoder!)
  hidden_dim: 128              # Hidden dim for off-diagonal covariance network
  n_layers: 2                  # Number of layers in covariance network
  beta: 1.0                    # KL weighting
  diagonal_transf: 'softplus'  # Diagonal transformation: relu, softplus, square, exp, sig
  reduced_diag: false          # ICTAI: false (apply transformation to prior diagonal)
  device: 'cuda'               # Device for training

data:
  root_dir: "data/epure"
  condition_csv: "data/epure/performances.csv"
  component_dirs: ["group_nc", "group_km", "bt", "fpu", "tpc"]
  condition_columns: ["d_cons_norm", "d_rigid_norm", "d_life_norm", "d_stab_norm"]
  prefix_column: "matching"
  filename_pattern: "{prefix}_{component}.png"
  split_column: "train"
  normalized: true

training:
  epochs: 100
  batch_size: 32               # ICTAI original: 32 (was 128!)
  num_workers: 4
  lr: 0.0005
  check_every: 10
  seed: 42

  # Loss configuration (ICTAI alignment)
  recon_loss: 'split_l1_mse'   # ICTAI original formula
  alpha_mse: 0.5
  recon_weights: [0.5, 0.5, 1, 0.5, 1]  # EPURE 5 components (no 'gi')

  # NOTE: Progressive masking NOT used for GMRF-MVAE (removed)

paths:
  output_dir: "outputs/gmrf_mvae/"
  samples_dir: "samples/gmrf_mvae/"

sampling:
  num_samples: 1000
  batch_sz: 64
  mode: conditional
