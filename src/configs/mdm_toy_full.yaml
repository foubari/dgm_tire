# Full training configuration for MDM with ToyTire dataset

model:
  type: mdm
  image_size: [64, 32]  # ToyTire: 64x32 (cropped from symmetric 64x64)
  dim: 64
  dim_mults: [1, 2, 4]
  num_classes: 4  # 3 components (group_nc, group_km, fpu) + 1 background = 4 classes
  timesteps: 500  # Number of diffusion timesteps
  loss_type: "vb_stochastic"  # Options: "vb_stochastic" or "vb_all"
  cond_drop_prob: 0.1  # Classifier-free guidance dropout probability

data:
  root_dir: "data/toy_epure/"
  condition_csv: "data/toy_epure/performances.csv"
  condition_columns: ["d_cons", "d_rigid", "d_life", "d_stab"]  # Performance metrics columns
  prefix_column: "matching"
  split_column: "train"
  resolution: [64, 32]  # ToyTire: 64x32 (cropped from symmetric 64x64)
  mask_format: "numpy"
  mask_path: null  # Will load from data/toy_epure/preprocessed/
  filename_pattern: "{prefix}.png"  # Not used for MDM
  normalized: false

training:
  epochs: 500
  batch_size: 64
  num_workers: 4
  lr: 0.0001
  eval_every: 50  # Evaluate every N epochs
  check_every: 50  # Save checkpoint every N epochs
  seed: 0

paths:
  output_dir: "outputs/mdm_toy/"
  samples_dir: "samples/mdm_toy/"

sampling:
  num_samples: 16
  batch_sz: 8
  guidance_scale: 2.0
  mode: conditional  # unconditional, conditional, or inpainting
  components: ["carcass", "crown"]  # For inpainting mode
